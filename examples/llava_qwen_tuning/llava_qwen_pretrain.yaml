# -----------------
# Model Parameters
# -----------------

model_name_or_path: /data-mnt/data/chwang/models/Qwen2.5-0.5B
template: qwen

# -----------------
# Method Parameters
# -----------------

stage: pt
do_train: true
finetuning_type: lora
lora_target: all

# --------------------
# Dataset Parameters
# --------------------

dataset: llava_v1_5_pretrain

# -------------------
# Output Parameters
# -------------------

output_dir: checkpoints/qwen2-0.5b-llava-pretrain
logging_steps: 10
save_steps: 1000
report_to: tensorboard
# plot_loss: true

# -----------------
# Train Parameters
# -----------------

per_device_train_batch_size: 2
gradient_accumulation_steps: 4
learning_rate: 1.0e-3
num_train_epochs: 1.0
lr_scheduler_type: cosine

# -----------------
# Optimization Parameters
# -----------------

fp16: true
flash_attn: true
use_unsloth: false
